<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="1 相关术语 分词常用的手段是基于字典的最长串匹配。">
<meta property="og:type" content="article">
<meta property="og:title" content="自然语言处理概述">
<meta property="og:url" content="http://yoursite.com/2018/06/15/自然语言简述/index.html">
<meta property="og:site_name" content="Alive">
<meta property="og:description" content="1 相关术语 分词常用的手段是基于字典的最长串匹配。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/n元模型计算.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/北大词性标注集1.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/TF-IDF公式.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/主题模型公式.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/句法树示例.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/清华数库.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/NNLM目标函数.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/C&W目标函数.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/DM模型示意图.jpg">
<meta property="og:image" content="http://yoursite.com/2018/06/15/自然语言简述/DBOW模型示意图.jpg">
<meta property="og:updated_time" content="2018-07-18T09:00:09.625Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="自然语言处理概述">
<meta name="twitter:description" content="1 相关术语 分词常用的手段是基于字典的最长串匹配。">
<meta name="twitter:image" content="http://yoursite.com/2018/06/15/自然语言简述/n元模型计算.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/06/15/自然语言简述/"/>





  <title>自然语言处理概述 | Alive</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Alive</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">dachun's blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/15/自然语言简述/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Deorlive_Wt">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://p2.gexing.com/G1/M00/CC/2B/rBACE1WjflOixlZpAACXLIEhLjg875.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Alive">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">自然语言处理概述</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-15T15:00:18+08:00">
                2018-06-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/06/15/自然语言简述/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/06/15/自然语言简述/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  11,483 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  41 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-相关术语"><a href="#1-相关术语" class="headerlink" title="1 相关术语"></a>1 相关术语</h2><ul>
<li>分词<br>常用的手段是基于字典的最长串匹配。<a id="more"></a></li>
<li>词性标注<br>词性一般指动词、名词、形容词等，比如我/r爱/v北京/ns天安门/ns。ns代表名词，v代表动词，都是标注。</li>
<li>命名实体识别<br>指从文本中识别具有特定类别的实体（通常是名词），例如人名、地名等。</li>
<li>句法分析<br>往往最终生成的结果是一棵句法分析树。句法分析可以解决传统词袋模型不考虑上下文的问题。“小李是小杨的班长”和“小杨是小李的班长”，这两句话，用词袋模型是相同的，但是句法分析可以分析出其中的主从关系。</li>
<li>指代消解<br>中文中代词出现的频率很高，它的作用的是用来表征前文出现过的人名、地名等。</li>
<li>情感识别<br>本质上是分类问题，常应用在舆情分析等领域。情感一般分为两类，即正面、负面，也可以在前面基础上加上中性类别。电商企业，情感识别可以分析商品评价的好坏，以此作为下一个环节的评判依据。通常可以基于词袋模型+分类器，或者现在流行的词向量模型+RNN。经过测试发现，后者比前者准确率略有提升。</li>
<li>纠错<br>在搜索技术和输入法等领域，可以基于N-Gram进行纠错，也可以通过字典树、有限状态机等方法进行纠错。</li>
<li>问答系统<br>往往需要语音识别、合成，自然语言理解、知识图谱等多项技术的配合才会实现得比较好。</li>
</ul>
<h2 id="2-自然语言处理层面"><a href="#2-自然语言处理层面" class="headerlink" title="2 自然语言处理层面"></a>2 自然语言处理层面</h2><ul>
<li>词法分析<br>包括汉语的分词和词性标注这两部分。</li>
<li>句法分析<br>业界存在三种比较主流的句法分析方法。<ul>
<li>短语结构句法体系，作用是识别出句子中的短语结构以及短语之间的层次句法关系</li>
<li>依存结构句法体系，作用是识别句子中词与词之间的相互依赖关系</li>
<li>深层文法句法分析，利用深层文法，例如词汇化树邻接文法，组合范畴文法等对句子进行深层的句法以及语义分析。复杂度高，不适合大规模数据。</li>
</ul>
</li>
<li>语义分析<br>最终目的是理解句子表达的真实语义。但是，语义应该采用什么表示形式一直困扰着研究者们，没有统一答案。语义角色标注是目前比较成熟的浅层语义分析技术。语义角色标注一般都在句法分析的基础上完成，句法结构对于语义角色标注的性能至关重要。</li>
</ul>
<h2 id="3-正则表达式在NLP中的应用"><a href="#3-正则表达式在NLP中的应用" class="headerlink" title="3 正则表达式在NLP中的应用"></a>3 正则表达式在NLP中的应用</h2><p>正则表达式的作用之一是将这些文档内容从非结构化转为结构化以便后续的文本挖掘，另一个作用就是去除“噪声”。</p>
<ul>
<li><p>3.1 匹配字符串</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">re.search(regex,<span class="keyword">string</span>)<span class="comment">#表示字符串是否有能够匹配，返回值True或者Dalse</span></span><br><span class="line">re.findall(regex,<span class="keyword">string</span>)<span class="comment">#返回所有被匹配到的字符或字符串</span></span><br><span class="line">list1=str1.<span class="built_in">split</span>(<span class="string">'。'</span>)</span><br><span class="line">regex=<span class="string">'^爬.'</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">line</span> <span class="keyword">in</span> list1:</span><br><span class="line">    <span class="keyword">if</span> re.search(regex,<span class="built_in">line</span>):</span><br><span class="line">        print <span class="built_in">line</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>3.2 特殊符号</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">'.'，            匹配任意一个字符</span><br><span class="line">'^a'，           匹配所有以字母a开头的字符串</span><br><span class="line">'a$'，           匹配所有以字母a结尾的字符串</span><br><span class="line">'[bcr]at'，      匹配“bat”“cat”以及“rat”。如果是要匹配的是[]，需要前面加上转义字符\，即\[\]</span><br><span class="line">r'\\'，          匹配\</span><br><span class="line">'[<span class="string">1-2</span>][<span class="symbol">0-9</span>]&#123;3&#125;'，匹配1000-2999之间的数字，3表示前面重复3次，即[<span class="string">0-9</span>][<span class="symbol">0-9</span>][<span class="string">0-9</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="4-中文分词"><a href="#4-中文分词" class="headerlink" title="4 中文分词"></a>4 中文分词</h2><p>主要归纳为“规则分词”“统计分词”和“混合分词（规则+统计）”这三个主要流派。规则分词是最早兴起的方法，主要是通过人工设立词库，按照一定方式进行匹配切分，其实现简单高效，但对新词很难进行处理。随后统计机器学习技术的兴起，应用于分词任务上后，就有了统计分词，能够较好应对新词发现等特殊场景。然而实践中，单纯的统计分词也有缺陷，那就是太过于依赖语料的质量，因此实践中多是采用这两种方法的结合，即混合分词。</p>
<ul>
<li>4.1 规则分词<br>基于规则的分词是一种机械分词方法，主要是通过维护词典，在切分语句时，将语句的每个字符串与词表中的词进行逐一匹配，找到则切分，否则不予切分，按照匹配切分的方式，有三种。<br>基于规则的分词简单高效，但是词典维护工程大，因为新词层出不穷。<ul>
<li>4.1.1 正向最大匹配法<br>首先有词典和待切分字符串，假设词典词语最大长度为i，从左向右取字符串前i个字符，然后匹配词典，如果匹配不了，则取前i-1个字符，继续匹配，直至匹配上或者只剩1个字符了。然后原始字符串去掉这个字符，继续重复同样的操作，取前i个字符。</li>
<li>4.1.2 逆向最大匹配法<br>首先字典需要逆序字典，然后从右向左取前i个字符，匹配，匹配不了，取前i-1个字符等，其他和正向最大匹配法原理一样。</li>
<li>4.1.3 双向最大匹配法<br>将正向最大匹配法得到的分词结果和逆向最大匹配法得到的结果进行比较，然后按照最大匹配原则，选取最终切分词的数量最少的作为结果。</li>
</ul>
</li>
<li><p>4.2 统计分词<br>基于统计的分词，一般两个步骤：(1)建立统计语言模型(2)对句子进行单词划分，然后对划分结果进行概率计算，获得概率最大的分词方式，用到了统计学习算法，如隐马尔科夫模型(HMM)、条件随机场(CRF)等</p>
<ul>
<li>4.2.1 语言模型<br>语言模型就是求长度为m的字符串的概率分布P(ω1,ω2,…,ωn),其中ω1到ωn代表文本中的各个字，P(ω1，ω2，…，ωm)=P(ω1)P(ω2|ω1)P(ω3|ω1，ω2)…P(ωi|ω1，ω2，…，ωi-1)…P(ωm|ω1，ω2，…，ωm-1)。<br>当文本过长时，计算难度大。一般用n元模型来降低难度，n元模型忽略距离大于等于n的上文词的影响。当n=2时，称为二元模型，只考虑前面1个词，P(ωi|ω1，ω2，…，ωi-1)=P(ωi|ωi-1)，一般二元模型采用的多。<br>一般使用频率计数的比例来计算n元条件概率,可用拉普拉斯平滑算法解决分子分母为0的问题 <img src="/2018/06/15/自然语言简述/n元模型计算.jpg" alt=""></li>
<li>4.2.2 HMM模型<ul>
<li>每个字在构造一个特定的词语时都占据着一个词位，即B（词首）、M（词中）、E（词尾）和S（单独成词）。通过求得每个字的词位，即可分词。</li>
<li>用λ=λ1λ2…λn代表输入的句子，n为句子长度，λi表示字，o=o1o2…on代表输出的标签，那么理想的输出即为：max=maxP(o1o2…on|λ1λ2…λn)，o即为B、M、E、S这4种标记。</li>
<li>期望求解的是max P(o|λ)，通过贝叶斯公式转而求解max P(λ|o)P(o)(分母为常数不需要求)。</li>
<li>假设一，马尔科夫假设。<br>P(λ|o)=P(λ1|o1)P(λ2|o2)…P(λn|on) </li>
<li>假设二，齐次马尔科夫假设，每个输出仅仅与上一个输出有关，即二元模型。<br>P(o)=P(o1)P(o2|o1)P(o3|o2)…P(on|on-1)</li>
<li>P(λ|o)P(o)～P(λ1|o1)P(o2|o1)P(λ2|o2)P(o3|o2)…P(on|on-1)P(λn|on) （3.10）。在HMM中，将P(λk|ok)称为发射概率，P(ok|ok-1)称为转移概率。HMM中，求解maxP(λ|o)P(o)的常用方法是Veterbi算法，它是一种动态规划方法。</li>
<li>语料库为分好词的句子，比如<a href="https://github.com/nlpinaction/learning-nlp/blob/master/chapter-3/data/trainCorpus.txt_utf8" target="_blank" rel="noopener">这里</a>。实际项目实战中，读者可通过扩充语料、词典补充等手段予以优化。</li>
</ul>
</li>
<li>4.2.3 其他统计分词算法<ul>
<li>条件随机场<br>是一种基于马尔可夫思想的统计模型，每个状态不止与他前面的状态有关，还与他后面的状态有关。</li>
<li>神经网络分词算法<br>通常采用CNN、LSTM等深度学习网络自动发现一些模式和特征，然后结合CRF、softmax等分类算法进行分词预测。</li>
</ul>
</li>
<li>4.2.4 优缺点<br>  对比机械分词法，这些统计分词方法不需耗费人力维护词典，能较好地处理歧义和未登录词，是目前分词中非常主流的方法。但其分词的效果很依赖训练语料的质量，且计算量相较于机械分词要大得多。</li>
</ul>
</li>
<li><p>4.3 混合分词<br>目前不管是基于规则的算法、还是基于HMM、CRF或者deep learning等的方法，其分词效果在具体任务中，其实差距并没有那么明显。实际工程应用中，多是基于一种分词算法，然后用其他分词算法加以辅助。最常用的方式就是先基于词典的方式进行分词，然后再用统计分词方法进行辅助。在保证词典分词准确率的基础上，对未登录词和歧义词有较好的识别，Jieba分词工具便是基于这种方法的实现。</p>
</li>
<li>4.4 JieBa<br>Jieba不是只有分词这一个功能，其是一个开源框架，提供了很多在分词之上的算法，如关键词提取、词性标注等。<br>提供了很多热门社区项目的扩展插件，如ElasticSearch、solr、lucene等。<br>Jieba分词结合了基于规则和基于统计这两类方法。首先基于前缀词典进行词图扫描，前缀词典是指词典中的词按照前缀包含的顺序排列，例如词典中出现了“上”，之后以“上”开头的词都会出现在这一部分，例如“上海”，进而会出现“上海市”。基于前缀词典可以快速构建包含全部可能分词结果的有向无环图。基于标注语料，使用动态规划的方法可以找出最大概率路径，并将其作为最终的分词结果。对于未登录词，Jieba使用了基于汉字成词的HMM模型，采用了Viterbi算法进行推导。<ul>
<li>4.4.1 三种分词模式<br>精确模式：试图将句子最精确地切开，适合文本分析，默认精准模式，jieba.cut(str1,HMM=True)。<br>全模式：把句子中所有可以成词的词语都扫描出来，速度非常快，但是不能解决歧义，jieba.cut(str1,cut_all=True)。<br>搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词,jieba.cut_for_search(str1)。</li>
<li>4.4.2 去除停用词<br>通用的<a href="https://github.com/dcexist/learning-nlp/blob/master/chapter-3/data/stop_words.utf8" target="_blank" rel="noopener">停用词表</a>,一般实践过程中，需要根据自己的任务，定期更新维护。</li>
<li>4.4.3 提高分词效果<br>需要定制自己的领域词典，用以提升分词的效果。Jieba分词就提供了这样的功能，用户可以加载自定义词典，jieba.load_userdict(‘./data/user_dict.txt’)</li>
</ul>
</li>
</ul>
<h2 id="5-词性标注与命名实体识别"><a href="#5-词性标注与命名实体识别" class="headerlink" title="5 词性标注与命名实体识别"></a>5 词性标注与命名实体识别</h2><ul>
<li><p>5.1 词性标注<br>词性，即名词、动词、形容词等</p>
<ul>
<li>5.1.1 词性标注最简单的方法是从语料库中统计每个词所对应的高频词性，将其作为默认词性。目前较为主流的方法是如同分词一样，将句子的词性标注作为一个序列标注问题来解决，分词中常用的如隐含马尔可夫模型、条件随机场模型等皆可在词性标注任务中使用。</li>
<li>5.1.2 中文领域中尚无统一的标注标准，较为主流的主要为北大的词性标注集和宾州词性标注集两大类，下图为部分北大词性标注集。<img src="/2018/06/15/自然语言简述/北大词性标注集1.jpg" alt=""></li>
<li>5.1.3 Jieba分词中的词性标注<br>Jieba的词性标注同样是结合规则和统计的方式，具体为在词性标注的过程中，词典匹配和HMM共同作用。<ul>
<li>正则表达式进行汉字判断，中文范围 ‘\u4E00-\u9FA5’,前面加上^，表示排除中文<br>re.compile(u’[^\u4E00-\u9FD5]’).sub(r’ ‘, str1)</li>
<li>在前缀词典中找出它所分出的词性，若在词典中未找到，则赋予词性为“x”（代表未知）。当然，若在这个过程中，设置使用HMM，且待标注词为未登录词，则会通过HMM方式进行词性标注。</li>
<li>若不符合上面的正则表达式，那么将继续通过正则表达式进行类型判断，分别赋予“x”“m”（数词）和“eng”（英文）。</li>
<li>在词性标注任务中，Jieba分词采用了simultaneous思想的联合模型方法，即将基于字标注的分词方法与词性标注结合起来，使用复合标注集。比如，对于名词“人民”，它的词性标注是“n”，而分词的标注序列是“BE”，于是“人”的标注就是“B_n”，“民”的标注就是“E_n”。<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import jieba.posseg as psg</span><br><span class="line"><span class="attribute">sent</span>=<span class="string">'中文分词是文本处理不可或缺的一步!'</span></span><br><span class="line"><span class="attribute">sent_list</span>=psg.cut(sent)</span><br><span class="line"><span class="keyword">for</span> w,t <span class="keyword">in</span> sent_list:</span><br><span class="line">	<span class="builtin-name">print</span> w,t</span><br><span class="line">	</span><br><span class="line">中文 nz</span><br><span class="line">分词 n</span><br><span class="line">是 v</span><br><span class="line">文本处理 n</span><br><span class="line">不可或缺 l</span><br><span class="line">的 uj</span><br><span class="line">一步 m</span><br><span class="line">! x</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>5.2 命名实体识别</p>
<ul>
<li>5.2.1 简介<ul>
<li>目的是识别语料中人名、地名、组织机构名等命名实体。由于这些命名实体数量不断增加，通常不可能在词典中穷尽列出，且其构成方法具有各自的规律性，因此，通常把对这些词的识别在词汇形态处理（如汉语切分）任务中独立处理，称为命名实体识别（Named Entities Recognition，NER）。数量、时间、日期、货币等实体识别通常可以采用模式匹配的方式获得较好的识别效果。</li>
<li>命名实体识别更侧重高召回率，但在信息检索领域，高准确率更重要。</li>
<li>命名实体识别效果的评判主要看实体的边界是否划分正确以及实体的类型是否标注正确。</li>
<li>相较于实体类别标注子任务，实体边界的识别更加困难。</li>
</ul>
</li>
<li>5.2.2 识别方法<br>分词主要有三种方式，主要有基于规则的方法、基于统计的方法以及二者的混合方法。这在整个NLP的各个子任务基本上也多是同样的划分方式，命名实体识别也不例外。<ul>
<li>基于规则的命名实体识别：依赖手工规则的系统，结合命名实体库，对每条规则进行权重赋值，然后通过实体与规则的相符情况来进行类型判断。</li>
<li>基于统计的命名实体识别：主流的基于统计的命名实体识别方法有隐马尔可夫模型、最大熵模型、条件随机场等。基于人工标注的语料，将命名实体识别任务作为序列标注问题来解决。对语料库的依赖比较大，而大规模通用语料库又比较少。</li>
<li>混合方法:在很多情况下是使用混合方法，结合规则和统计方法。借助规则知识提前进行过滤修剪处理，序列标注方式是目前命名实体识别中的主流方法。</li>
</ul>
</li>
<li>5.2.3 条件随机场<br>在大量真实语料中，观察序列更多的是以一种多重的交互特征形式表现出来，观察元素之间广泛存在长程相关性，HMM的效果就受到了制约。条件随机场的思想来源于HMM，每个状态不止与他前面的状态有关，还与他后面的状态有关。<ul>
<li>由n个字符构成的NER的句子，每个字符的标签都在已知标签集合（“B”“M”“E”“S”和“O”）中，为每个字符选定标签后，形成了一个随机场(注意，标签是选定的)。加一些约束，如所有字符的标签只与相邻的字符的标签相关，那么即马尔可夫随机场问题。</li>
<li>假设马尔可夫随机场中有X和Y两种变量，X一般是给定的，Y是在给定X条件下的输出。如X是字符，Y为标签，P(X|Y)就是条件随机场。通过贝叶斯，最后转化求max P(y|x)。实际中，假设X和Y结构相同，即X=(X1，X2，X3，…，Xn)，Y=(Y1，Y2，Y3，…，Yn) </li>
<li>定义：设X=(X1，X2，X3，…，Xn)和Y=(Y1，Y2，Y3，…，Yn)均为随机变量序列，若在X的条件下，Y的条件概率分布P(Y|X)构成条件随机场，且满足马尔可夫性：P(Yi|X，Y1，Y2，…，Yn)=P(Yi|X，Yi-1，Yi+1) ，则称P(Y|X)为线性链的条件随机场，一般所说的CRF指的就是线性链CRF。</li>
<li>对句子“我来到牛家村”进行标注，正确标注后的结果应为“我/O来/O到/O牛/B家/M村/E”。采用线性链CRF来进行解决，（O，O，O，B，M，E）是其一种标注序列，（O，O，O，B，B，E）是另一种，选择很多，NER任务中就是找出最靠谱的作为句子标注。</li>
<li>在CRF中，定义一个特征函数集合，然后使用这个特征集合为标注序列进行打分，据此选出最靠谱的标注序列。比如如果标注中出现连续两个“B”结构的标注序列，则给它低分。</li>
<li>在CRF中有两种特征函数，分别为转移函数tk(yi-1，yi，i)和状态函数sl(yi，X，i)。前者依赖于当前和前一个位置，表示从标注序列中位置i-1的标记yi-1转移到位置i上的标记yi的概率。后者依赖当前位置，表示标记序列在位置i上为标记yi的概率。</li>
<li>通过特征函数打分，使得 arg max P(y|x) ，求得合适的标记y，x为特征函数中的x。该问题与HMM求解最大可能序列路径一样，也是采用的Veterbi算法。</li>
<li>解决标注问题时，HMM和CRF效果都比较好，不过CRF能够捕捉全局的信息和灵活的特征设计，因此一般效果要比HMM好，但实现复杂度高。</li>
</ul>
</li>
<li>5.2.4 总结<br>当将分词、词性标注和命名实体识别都作为标注任务时，采用HMM和CRF都是可行的，不同的是标签的区别。<br>在命名实体识别中，在切完词、标注完词性后，再做识别任务，效果要比单纯的字标注要好很多。</li>
</ul>
</li>
<li><p>5.3 实战</p>
<ul>
<li>5.3.1 日期识别<ul>
<li>背景<br>现有一个基于语音问答的酒店预订系统，其根据用户的每句语音进行解析，识别出用户的酒店预订需求，如入住时间等。用户的语音在发送给后台进行请求时已经转换成中文文本，然而由于语音转换工具的识别问题，许多日期类的数据并不是严格的数字，会出现诸如“六月12”“2016年八月”“20160812”“后天下午”等形式。这里识别出每个请求文本中可能的日期信息，并将其转换成统一的格式进行输出。例如“我要今天住到明天”（假设今天为2017年10月1号），那么通过日期解析后，应该输出为“2017-10-01”和“2017-10-02”。</li>
<li>方法<ul>
<li>自定义规则，“今天”“明天”对时间的映射。这里由于是酒店入住，基本不会出现“前天”“昨天”等情况，因此未予添加</li>
<li>利用Jieba词性标注的功能，提取其中“m”（数字）“t”（时间）词性的词</li>
<li>正则表达式匹配</li>
</ul>
</li>
<li>优缺点<ul>
<li>相较于基于统计的方法，规则方法无须在系统建设初期为搜集数据标注训练而苦恼，能够快速见效。</li>
<li>采用规则去覆盖所有的语言场景是不太现实的。</li>
</ul>
</li>
</ul>
</li>
<li><p>5.3.2 地名识别<br>采用基于条件随机场的方法来完成地名识别任务，CRF++的安装，Windows系统用户可去官网<a href="https://taku910.github.io/crfpp/" target="_blank" rel="noopener">https://taku910.github.io/crfpp/</a> 下载二进制版本，Linux或Mac用户可从Github（ <a href="https://github.com/taku910/crfpp" target="_blank" rel="noopener">https://github.com/taku910/crfpp</a> ）或官网获取源码进行安装。</p>
<ul>
<li>1 确定标签体系<br>如同分词和词性标注一样，命名实体识别也有自己的标签体系。可以按照自己的想法自行设计，也采用地理位置标记规范，即针对每个字符标记为“B”“E”“M”“S”“O”中的一个。</li>
<li><p>2 语料数据处理</p>
<ul>
<li><p>CRF++的训练数据要求一定的格式，一般是一行一个token，一句话由多行token组成，多个句子之间用空行分开。其中每行又分成多列，除最后一列以外，其他列表示特征。因此一般至少需要两列，最后一列表示要预测的标签（“B”“E”“M”“S”“O”）。比如只采用字符这一个维度作为特征，以“我去北京饭店。”为例，结果如下（最后一行为空行）：</p>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">我	<span class="keyword">O</span> </span><br><span class="line">去	<span class="number">0</span></span><br><span class="line">北	B</span><br><span class="line">京	M</span><br><span class="line">饭	M</span><br><span class="line">店	<span class="keyword">E</span></span><br><span class="line">。	<span class="keyword">O</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>语料数据：比如1998年人民日报分词数据集，其主要是一个词性标注集。但可以使用其中被标记为“ns”的部分来构造地名识别语料。</p>
</li>
</ul>
</li>
<li>3 特征模块设计<ul>
<li>CRF有特征函数，它是通过定义一些规则来实现的，而这些规则就对应着CRF++中的特征模板。</li>
<li>CRF++有两种模板类型，第一种是字母U开头，为Unigram template，CRF++会自动为其生成一个特征函数集合。第二种以字母B开头，表示Bigram template，系统会自动产生当前输出与前一个输出token的组合，根据该组合构造特征函数。</li>
<li>特征模板需要自己定义</li>
</ul>
</li>
<li>4 模型训练与调试<br>训练和测试的命令：crf_learn、crf_test。这里考虑的特征维度也少（只考虑了字符本身维度），若采用词性标注后的文本作为语料，将词性作为特征加入训练集中，会使模型效果提升。</li>
<li>5 其他问题<br>该程序针对一些场景能够很好地进行识别，但是在遇到诸如“回龙观”“南锣鼓巷”“北京南站”等词时识别效果并不好。这种情况在实际项目中会经常遇到，通常有以下解决办法：<ul>
<li>扩展语料，改进模型。如加入词性特征，调整分词算法等。</li>
<li>整理地理位置词库。在识别时，先通过词库匹配，再采用模型进行发现。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="6-关键词提取算法"><a href="#6-关键词提取算法" class="headerlink" title="6 关键词提取算法"></a>6 关键词提取算法</h2><ul>
<li>6.1 概述<ul>
<li>算法分为有监督和无监督两类。</li>
<li>有监督通过分类进行，构建一个词表，通过判断每个文档与词表中每个词的匹配程度，以类似打标签的方式，达到关键词提取的效果。有监督较高精度，但缺点是需要大批量的标注数据，人工成本高。固定的词表有时很难将新信息的内容表达出来，人工维护成本高。</li>
<li>无监督不需要人工生成、维护的词表，也不需要人工标准语料辅助进行训练。常用的有TF-IDF算法、TextRank算法和主题模型算法（包括LSA、LSI、LDA等）。</li>
</ul>
</li>
<li>6.2 TF-IDF<br>词频-逆文档频率，词频需要做归一化，整个文档中频次/总词数，BOW是词袋模型，即词的出现次数，未归一化处理。TF-IDF公式如下：<img src="/2018/06/15/自然语言简述/TF-IDF公式.jpg" alt=""><br>文本中还有信息能对关键词提取起作用，比如每个词的词性、出现的位置等。在文本中，名词带有更多关键信息，对名词赋予更高权重，能使提取出来的关键词更合理。某些场景中，文本的起始段落和末尾段落比起其他部分的文本更重要，对出现在这些位置的词赋予更高权重，也能提高关键词提取。</li>
<li>6.3 TextRank算法<br>可以脱离语料库(整个数据集)的背景，仅对单篇文档进行分析就可以提取该文档的关键词。</li>
<li>6.4 LSA/LSI/LDA算法<ul>
<li>6.4.1 介绍<ul>
<li>有些关键词并不一定会显式地出现在文档当中，如一篇讲动物生存环境的科普文，通篇介绍了狮子老虎鳄鱼等各种动物的情况，但是文中并没有显式地出现动物二字，这种情况下，前面的两种算法不能提取出动物这个隐含的主题信息，这时候就需要用到主题模型。</li>
<li>主题模型认为在词与文档之间没有直接的联系，它们应当还有一个维度将它们串联起来，主题模型将这个维度称为主题。</li>
<li>每个文档对应着一个或多个的主题，而每个主题对应着一个或多个的词语，通过主题，就可以得到每个文档的词分布。</li>
<li>已知数据集中，每个词和文档对应的p(wi|dj)都是已知的。而主题模型就是根据这个已知信息，计算p(wi|tk)和p(tk|dj)的值，含义可以理解为一篇文档中某个词语的重要性=一篇文档中属于某个主题的重要性*某个词语在该主题中的重要性，公式:<img src="/2018/06/15/自然语言简述/主题模型公式.jpg" alt=""></li>
<li>p(wi|tk)和p(tk|dj)的求解常用方法就是LSA（LSI）和LDA。其中LSA主要是采用SVD（奇异值分解）的方法进行暴力破解，而LDA则是通过贝叶斯学派的方法对分布信息进行拟合。</li>
</ul>
</li>
<li>6.4.2 LSA/LSI算法<br>LSA（Latent Semantic Analysis，潜在语义分析）和LSI（Latent Semantic Index，潜在语义索引），通常被认为是同一种算法。LSA和LSI都是对文档的潜在语义进行分析，但是潜在语义索引在分析后，还会利用分析的结果建立相关的索引。<ul>
<li>步骤<ul>
<li>使用BOW模型将每个文档表示为向量</li>
<li>将所有的文档词向量拼接起来构成词–文档矩阵（m×n）</li>
<li>对词–文档矩阵进行奇异值分解（SVD）操作（[m×r]·[r×r]·[r×n]）</li>
<li>根据SVD的结果，将词–文档矩阵映射到一个更低维度k（[m×k]·[k×k]·[k×n]，0&lt;k&lt;r）的近似SVD结果，每个词和文档都可以表示为k个主题构成的空间中的一个点。计算每个词和文档的相似度（相似度计算可以通过余弦相似度或者是KL相似度进行，第一个矩阵的每一行(长度k，代表词语)和第三个矩阵的每一列(长度k，代表文档)计算相似度），可以得到每个文档中对每个词的相似度结果，取相似度最高的一个词即为文档的关键词(这个词不一定是构成文档中的词语，可能是通过训练集获得的新词)。</li>
</ul>
</li>
<li>不足<br>1)SVD的计算复杂度高，特征空间维度大时计算效率低下。当新文档进入到已有特征空间时，需要对整个空间重新训练，以得到加入新文档后对应的分布信息。<br>2)改进提出了pLSA算法，通过使用EM算法对分布信息进行拟合替代了使用SVD进行暴力破解，一定程度上解决了LSA的部分缺陷，但是LSA仍有较多不足。<br>3)在pLSA的基础上，引入了贝叶斯模型，实现了现在topic model的主流方法——LDA（Latent Dirichlet Allocation，隐含狄利克雷分布）。</li>
</ul>
</li>
<li>6.4.3 LDA算法<ul>
<li>理论基础是贝叶斯理论，拟合出词–文档–主题的分布。</li>
<li>假设文档中主题的先验分布和主题中词的先验分布都服从狄利克雷分布（隐含狄利克雷分布），先验分布+数据（似然）=后验分布。对已有数据集的统计，得到每篇文档中主题的多项式分布和每个主题对应词的多项式分布。</li>
<li>通过先验的狄利克雷分布和观测数据得到的多项式分布，得到一组Dirichlet-multi共轭，并据此来推断文档中主题的后验分布和主题中词的后验分布，就是需要的结果，其中一种主流的方法就是吉布斯采样。</li>
<li>通过这个分布信息计算文档与词的相似性，继而得到文档最相似的词列表。</li>
</ul>
</li>
<li>6.4.4 总结<br>一般情况下，使用词性过滤仅保留名词作为关键词更符合要求，但有些场景对其他词性的词有特殊要求，可以根据场景选择需要过滤的词性。还可以通过调整关键词提取数量、主题模型的主题数量等参数以及增大训练集的方式提高模型表现效果。</li>
</ul>
</li>
</ul>
<h2 id="7-句法分析"><a href="#7-句法分析" class="headerlink" title="7 句法分析"></a>7 句法分析</h2><ul>
<li>7.1 概述<ul>
<li>介绍<ul>
<li>句法分析是机器翻译的核心技术，主要任务是识别出句子所包含的句法成分以及这些成分之间的关系，一般以句法树来表示句法分析的结果。</li>
<li>句法分析（Parsing）是从单词串得到句法结构的过程，而实现该过程的工具或程序被称为句法分析器（Parser）。</li>
<li>分为完全句法分析和局部句法分析两种，差别在于：完全句法分析以获取整个句子的句法结构为目的；而局部句法分析只关注于局部的一些成分，例如常用的依存句法分析就是一种局部分析方法。</li>
<li>本质是一套面向候选树的评价方法，会给正确的句法树赋予一个较高的分值，而给不合理的句法树赋予一个较低的分值，这样就可以借用候选句法树的分值进行消歧。</li>
</ul>
</li>
<li>难点<ul>
<li>歧义</li>
<li>搜索空间大<br>句法分析是一个极为复杂的任务，候选树个数随句子增多呈指数级增长，搜索空间巨大，因此必须设计出合适的解码器。</li>
</ul>
</li>
<li>方法<br>可以简单地分为基于规则的方法和基于统计的方法两大类。基于规则的方法在处理大规模文本时，语法规则覆盖有限。随着大规模标注树库的建立，基于统计学习模型的句法分析方法开始兴起，当下最流行的是PCFG（Probabilistic Context Free Grammar）方法。</li>
</ul>
</li>
<li>7.2 句法分析的数据集与评测方法<ul>
<li>数据集<br>句法分析的数据集是一种树形的标注结构，称为树库，如下所示：<img src="/2018/06/15/自然语言简述/句法树示例.jpg" alt="">中文树库著名的有中文宾州树库（Chinese TreeBank，CTB）、清华树库（Tsinghua Chinese TreeBank，TCT）和台湾中研院树库，其中CTB是目前绝大多数的中文句法分析研究的基准语料库。不同树库的标记体系不一样，解释不能通用，下图为清华数库部分标记：<img src="/2018/06/15/自然语言简述/清华数库.jpg" alt=""></li>
<li>评测方法<br>主流句法分析评测方法是PARSEVAL评测体系，指标有准确率、召回率、交叉括号数。交叉括号表示分析得到的某一个短语的覆盖范围与标准句法分析结果的某个短语的覆盖范围存在重叠又不存在包含关系，即构成了一个交叉括号。</li>
</ul>
</li>
<li>7.3 常用方法<br>相较于词法分析（分词、词性标注或命名实体识别等），句法分析成熟度要低上不少。以短语结构树为目标的句法分析器，目前应用最广泛，与很多其他形式语法对应的句法分析器都能通过对短语结构语法（特别是上下文无关文法）的改造而得到，句法分析属于NLP中较为高阶的问题。<ul>
<li>基于PCFG的句法分析<br>PCFG是上下文无关文法的扩展，可以计算分析树的概率值。PCFG衍生出了各种形式的算法，包括基于单纯PCFG、基于词汇化和基于子类划分PCFG的句法分析方法等。</li>
<li>基于最大间隔马尔可夫网络的句法分析<br>最大间隔是SVM中的理论，马尔可夫网络是概率图模型中一种具备一定结构处理关系能力的算法。最大间隔马尔可夫网络（Max-Margin Markov Networks）是这两者的结合，能够解决复杂的结构化预测问题，尤为适合用于句法分析任务。这是一种判别式的句法分析方法，通过丰富特征来消解分析过程中产生的歧义。如果要实现多元分类，可以使用多个二分类模型，每个模型分别识别一个短语标记，组合多分类器即可完成句法分析。</li>
<li>基于CRF的句法分析<br>当将句法分析作为序列标注问题来解决时，同样可以采用条件随机场（CRF）模型。可以采用清华树库，设计特征模板，然后训练一个基于CRF++的模型，并进行测试。</li>
<li>基于移进–归约的句法分析模型<br>移动-规约是一种自下而上的方法，从输入串开始，逐步进行“规约”，操作基本数据结构是堆栈。应用于中文时，对词性非常敏感，需要和准确度较高的词性标注工具一块使用。</li>
</ul>
</li>
<li>7.4 使用Stanford Parser的PCFG算法进行句法分析<ul>
<li>介绍<ul>
<li>Stanford Parser是斯坦福大学自然语言小组开发的开源句法分析器，是基于概率统计句法分析的一个Java实现。以权威的宾州树库作为分析器的训练数据，还支持分词和词性标注、短语结构、依存关系等输出，支持多个语言接口。</li>
</ul>
</li>
<li>安装<ul>
<li>需安装JDK，底层JAVA实现</li>
<li>需安装nltk库，因为Python封装是在nltk库中实现的，主要使用nltk.parse中的Stanford模块。</li>
<li>需要下载Stanford Parser的jar包，主要有两个：stanford-parser.jar和stanford-parser-3.8.0-models.jar。</li>
</ul>
</li>
<li>实战<br>对“他骑自行车去了菜市场”这句话进行句法分析以及可视化操作，<a href="https://github.com/dcexist/learning-nlp/blob/master/chapter-6/PCFG.py" target="_blank" rel="noopener">代码中</a>Stanford Parser的句法分析器接收的输入是分词完后以空格隔开的句子，stanford-parser-3.8.0-models.jar是已经训练好的模型，解压jar包可以看到支持的算法。</li>
</ul>
</li>
<li>7.5 总结<ul>
<li>和词法分析（分词、词性标注和命名实体识别等）相比，句法分析算法实际性能离真正实用化有距离，原因在于语言学理论和实际的自然语言应用之间存在很大差距。</li>
<li>实践中，句法分析常结合一定规则来辅助解决一些任务。如模板解析类的任务，通过句法分析进行语义标注，提取其中主谓宾关系，再通过规则模板标出重要的角色信息和行为。</li>
</ul>
</li>
</ul>
<h2 id="8-文本向量化"><a href="#8-文本向量化" class="headerlink" title="8 文本向量化"></a>8 文本向量化</h2><ul>
<li>8.1 向量化算法word2vect<br>认为上下文相似的词，其语义也相似。利用上下文分布表示词义的方法，这类方法就是有名的词空间模型（word space model）。神经网络词向量模型根据上下文与目标词之间的关系进行建模。<ul>
<li>神经网络语言模型<ul>
<li>神经网络语言模型（Neural Network Language Model，NNLM），和传统方法估算P(ωi|ωi-(n-1)，…，ωi-1)不同，NNLM模型直接通过一个神经网络结构对n元条件概率进行估计。输入的样本是，依次从文本取n-1个词，预测第n个词的概率。比如某个输入样本是x=[v(wi-(n-1));…;v(wi-2);v(wi-1)] ，输出y=[v(wi)]</li>
<li>NNLM模型使用低维紧凑的词向量对上文进行表示，解决了词袋模型带来的数据稀疏、语义鸿沟等问题；另一方面，在相似的上文语境中，NNLM模型可以预测出相似的目标词。例如，A=“一只小狗躺在地毯上”出现了2000次，B=“一只猫躺在地毯上”出现了1次。根据频率，P(A)要远远大于P(B)，而唯一的区别在于猫和狗，这两个词在词义和语法上都相似，而P(A)远大于P(B)显然是不合理的，采用NNLM计算则得到的P(A)和P(B)是相似的。每个词的输出概率y(ωi)即为所对应的点，将所有词连接，即组成了向量。</li>
<li>NNLM模型的目标是构建一个语言概率模型，最费时的部分当属隐藏层到输出层的权重计算。简单的NNLM模型只有三层，输入层、隐藏层和输出层。</li>
<li>希望能够在得知上文的情况下，知道y(wi)的概率。而y(wi)概率越大，说明上文越有效。则在语料库D中最大化y(ωi)便是NNLM模型的目标函数，如下<img src="/2018/06/15/自然语言简述/NNLM目标函数.jpg" alt=""></li>
</ul>
</li>
<li>C&amp;W模型<ul>
<li>C&amp;W是以生成词向量为目标的模型，如果n元短语在语料库中出现过，那么模型会给该短语打高分；如果是未出现在语料库中的短语则会得到较低的评分。</li>
<li>C&amp;W模型的输入层就包含了目标词，其输出层也变为一个节点，该节点输出值的大小代表n元短语的打分高低。相应的，C&amp;W模型的最后一层运算次数为|h|(输出层上一层神经元个数)，远低于NNLM模型的|V|×|h|(词语数目*输出层上一层神经元个数)次。较NNLM模型而言，C&amp;W模型可大大降低运算量。</li>
<li>C&amp;W模型最小化目标函数:<img src="/2018/06/15/自然语言简述/C&amp;W目标函数.jpg" alt=""> 1-(score(ω,c)-score(ω’,c))，其中(ω,c)表示正样本，来自语料库抽取的n元短语，为保证上下文词数一致，n为奇数，ω是目标词，c表示目标词的上下文语境；(ω’,c)表示负样本，负样本是将正样本序列中的中间词替换成其他词得到的。希望(score(ω,c)-score(ω’,c))越大越好，表示正样本得分高负样本得分低，越大，目标函数值越小，因此需要最小化目标函数。</li>
</ul>
</li>
<li>CBOW模型和Skip-gram模型<br>在NNLM和C&amp;W模型的基础上保留其核心部分，得到了CBOW（Continuous Bag of-Words）模型和Skip-gram模型。<ul>
<li>CBOW模型(连续词袋模型)<ul>
<li>输入层是语义上下文的表示(输出层是这段文本的中间词?)，去掉了隐藏层，大幅提升运算速率，预测下一个词的概率。</li>
<li>使用上下文各词的词向量的平均值替代NNLM模型各个拼接的词向量，如”the cat sat”这句话，首先用固定长度的不同词向量表示上文的三个词语，接着将这三个词向量求平均组成上文的向量化表示。</li>
<li>目标函数和NNLM模型类似，参考上文。</li>
</ul>
</li>
<li>Skip-gram模型<br>同样去掉了隐藏层，但与CBOW模型输入上下文词的平均词向量不同，Skip-gram模型是从目标词ω的上下文中选择一个词，将其词向量组成上下文的表示。</li>
<li>总结<br>Skip-gram和CBOW实际上是word2vec两种不同思想的实现：CBOW的目标是根据上下文来预测当前词语的概率，且上下文所有的词对当前词出现概率的影响的权重是一样的，因此叫continuous bag-of-words模型。Skip-gram刚好相反，其是根据当前词语来预测上下文概率的。在实际使用中，算法本身并无高下之分，可根据最后呈现的效果来进行算法选择。</li>
</ul>
</li>
</ul>
</li>
<li>8.2 向量化算法doc2vec/str2vec<ul>
<li>利用word2vec技术计算词语间的相似度效果良好，也可计算句子或者其他长文本间的相似度。对文本分词后提取关键词，用词向量表示这些关键词，接着对关键词向量求平均或者将其拼接，最后利用词向量计算文本间的相似度。但丢失了文本中的语序信息，例如“小王送给小红一个苹果”和“小红送给小王一个苹果”，组成两个句子的词语相同，但表达信息不同。</li>
<li>在word2vec的基础上提出了文本向量化（doc2vec），又称str2vec和para2vec。doc2vec是word2vec的升级，doc2vec不仅提取了文本的语义信息，而且提取了文本的语序信息。在一般的文本处理任务中，会将词向量和段向量相结合使用以期获得更好的效果。</li>
<li>doc2vec技术存在两种模型——Distributed Memory（DM）和Distributed Bag of Words（DBOW），分别对应word2vec技术里的CBOW和Skip-gram模型。与CBOW模型类似，DM模型试图预测给定上下文中某单词出现的概率，只不过DM模型的上下文不仅包括上下文单词而且还包括相应的段落。DBOW则在仅给定段落向量的情况下预测段落中一组随机单词的概率，与Skip-gram模型只给定一个词语预测目标词概率分布类似。<ul>
<li>DM模型<br>增加了一个与词向量长度相等的段向量，如段落paragraph ID也是先映射成一个向量，即paragraph vector。paragraph vector与word vector的维数虽然一样，但是代表两个不同的向量空间。如”the cat sat”这句话，首先用固定长度的不同词向量表示上文的三个词语，接着将这三个词向量和段落向量拼接/求平均组成上文的向量化表示，然后将其输入softmax层。在一个句子或者文档的训练过程中，paragraph ID保持不变，共享着同一个paragraph vector，相当于每次在预测单词的概率时，都利用了整个句子的语义。在预测阶段，给待预测的句子新分配一个paragraph ID，词向量和输出层softmax的参数保持训练阶段得到的参数不变，重新利用随机梯度下降算法训练待预测的句子。待误差收敛后，即得到待预测句子的paragraph vector，如下图所示：<img src="/2018/06/15/自然语言简述/DM模型示意图.jpg" alt=""></li>
<li>DBOW模型<br>DM模型通过段落向量和词向量相结合的方式预测目标词的概率分布，而DBOW模型的输入只有段落向量，通过一个段落向量预测段落中某个随机词的概率分布，如下图所示:<img src="/2018/06/15/自然语言简述/DBOW模型示意图.jpg" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>8.3 实战<ul>
<li>8.3.1 词向量训练<ul>
<li>1 中文语料预处理<br>采用维基百科里的中文网页作为训练语料库，<a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2" target="_blank" rel="noopener">最新语料</a>是xml格式的，需要进行处理，如将繁体转简体以及分词等。</li>
<li>2 向量化训练<br>利用gensim模块的Word2Vect读取语料，然后产生词向量，保存模型，需要时调用。</li>
</ul>
</li>
<li>8.3.2 段落向量的训练<br>这里不将每个文档进行分词，而是直接将转换后的简体文本保留。doc2vec在训练时能够采用tag信息来更好地辅助训练（表明是同一类doc），相对word2vec模型，输入文档多了一个tag属性。训练产生段落向量，保存<a href="https://pan.baidu.com/s/1nwTpzHB" target="_blank" rel="noopener">模型</a>，需要时调用。</li>
<li>8.3.3 利用word2vec和doc2vec计算网页相似度<ul>
<li>word2vec<br>抽取网页新闻中的关键词，接着将关键词向量化，然后将得到的各个词向量相加(而不是拼接)，最后得到的一个词向量总和代表网页新闻的向量化表示，利用这个总的向量计算网页相似度。</li>
<li>doc2vec<br>主要包括如下三个步骤：①预处理；②文档向量化；③计算文本相似。</li>
<li>总结<br>doc2vec方法计算的相似度为0.87高于word2vec计算的0.66，通过阅读前两篇新闻，知道这两篇新闻极为相似，因此可以判断doc2vec计算文本相似度的方法更胜一筹。这是因为：doc2vec不仅利用了词语的语义信息而且还综合了上下文语序信息，而word2vec则丢失了语序信息；word2vec方法中的关键词提取算法准确率不高，丢失了很多关键信息。</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/11/推荐系统简述/" rel="next" title="推荐系统概述">
                <i class="fa fa-chevron-left"></i> 推荐系统概述
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://p2.gexing.com/G1/M00/CC/2B/rBACE1WjflOixlZpAACXLIEhLjg875.jpg"
                alt="Deorlive_Wt" />
            
              <p class="site-author-name" itemprop="name">Deorlive_Wt</p>
              <p class="site-description motion-element" itemprop="description">戎马一生，天下青山一样</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/idachun" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/3198677493?refer_flag=1001030201_&is_all=1" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-globe"></i>Weibo</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-相关术语"><span class="nav-text">1 相关术语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-自然语言处理层面"><span class="nav-text">2 自然语言处理层面</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-正则表达式在NLP中的应用"><span class="nav-text">3 正则表达式在NLP中的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-中文分词"><span class="nav-text">4 中文分词</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-词性标注与命名实体识别"><span class="nav-text">5 词性标注与命名实体识别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-关键词提取算法"><span class="nav-text">6 关键词提取算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-句法分析"><span class="nav-text">7 句法分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-文本向量化"><span class="nav-text">8 文本向量化</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2018/06/15/自然语言简述/';
          this.page.identifier = '2018/06/15/自然语言简述/';
          this.page.title = '自然语言处理概述';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search、xml.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  
</body>
</html>
